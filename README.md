# Enhanced-Q-A-Chatbot-Using-Ollama-with-Mistral-and-Gemma2B-Models
Enhanced Q&amp;A Chatbot Using Ollama, Mistral, and Gemma2B Models for accurate and context-aware conversational interactions.

## Overview
This project presents an advanced Q&A chatbot built with the Ollama framework, utilizing the Mistral and Gemma2B models. The chatbot is designed to provide accurate and contextually relevant responses to user inquiries, enhancing user interaction through natural language processing.

## Features
- **Multimodal Support**: Leverages the capabilities of both Mistral and Gemma2B models to improve response accuracy.
- **User-Friendly Interface**: Built with Streamlit for an intuitive user experience.
- **Configurable Parameters**: Allows users to adjust model settings such as temperature and max tokens for tailored responses.
- **Environment Setup**: Utilizes dotenv for easy management of API keys and configurations.

## Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/offcool/Enhanced-Q-A-Chatbot-Using-Ollama-with-Mistral-and-Gemma2B-Models
   cd Enhanced-Q-A-Chatbot-Using-Ollama-with-Mistral-and-Gemma2B-Models

Install the required packages: - pip install -r requirements.txt
Run the application : streamlit run app_Ollama.py

Open your web browser and navigate to http://localhost:8501 to interact with the chatbot.

